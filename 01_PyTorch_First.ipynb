{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[PyTorch](https://pytorch.org/) Basic**\n",
    "\n",
    "Tensorflow vs PyTorch\n",
    "- Tensorflow 1.X -> low level\n",
    "- Tensorflow 2.X -> high level --> with keras\n",
    "\n",
    "When optimizing large and complex functions, such as neural networks, especially with substantial datasets, we rely on optimization techniques. PyTorch offers key functionalities to streamline this process, including:\n",
    "- Automatic Differentiation: PyTorch's ([TORCH.AUTOGRAD](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#a-gentle-introduction-to-torch-autograd)) module automatically computes gradients for complex mathematical functions, making backpropagation and optimization much easier to implement. \n",
    "- Comprehensive Training Tools: PyTorch provides a wide range of utilities for training neural networks, including predefined optimizers, loss functions, and easy-to-use model building frameworks, all designed to enhance efficiency and flexibility in the training process.\n",
    "\n",
    "[옵션] ```pip install ipywidgets``` (Jupyter notebook으로 실행하는 경우 불필요한 경고가 뜨는 것을 방지할 수 있음)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensor**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Creating tensors from lists - tensors, like numpy arrays, are also multidimensional arrays, but with additional functionalities for deep learning.\n",
    "\n",
    "You can determine the location of a tensor (whether on CPU or GPU) by using the ```tensor.device``` command."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Numpy and Tensor\n",
    "\n",
    "To improve training speed, it is recommended to minimize unnecessary copying of data in PyTorch whenever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_np = np.array(data)\n",
    "\n",
    "x_data = torch.tensor(x_np, dtype=torch.int16) \n",
    "print(x_data.shape, x_data.dtype)\n",
    "print(x_data)\n",
    "\n",
    "x_data = torch.from_numpy(x_np) \n",
    "print(x_data.shape, x_data.dtype)\n",
    "print(x_data)\n",
    "\n",
    "x_data = torch.as_tensor(x_np, dtype=torch.float) \n",
    "print(x_data.shape, x_data.dtype)\n",
    "print(x_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ones, zeros, randon numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3,)\n",
    "ones_tensor = torch.ones(shape) \n",
    "zeros_tensor = torch.zeros(shape) \n",
    "rand_tensor = torch.rand(shape)\n",
    "\n",
    "# float32\n",
    "\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_np = np.array(data)\n",
    "x_data = torch.tensor(x_np, dtype=torch.float)\n",
    "\n",
    "x_ones = torch.ones_like(x_data) \n",
    "x_zeros = torch.zeros_like(x_data)\n",
    "x_rand = torch.rand_like(x_data)\n",
    "\n",
    "print(x_ones)\n",
    "print(x_zeros)\n",
    "print(x_rand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "c = a * b \n",
    "\n",
    "print(c)\n",
    "print(c.sum()) \n",
    "print(c.sum().item()) \n",
    "print(type(c.sum().item())) # <class 'int'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "b1 = a[0:3]\n",
    "b2 = a[3:6]\n",
    "\n",
    "print(b1)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "print(\"a shape:\", a.shape)\n",
    "print(\"b shape:\", b.shape)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "t = torch.cat([a, b], dim = 0) \n",
    "\n",
    "print(\"t shape:\", t.shape)\n",
    "print(t)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "t = torch.cat([a, b], dim = 1) \n",
    "\n",
    "print(\"t shape:\", t.shape)\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to use GPU..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "\n",
    "$y = 2.0 \\cdot x^5 + 1.0$]\n",
    "\n",
    "When $x=0.5$, the gradient of $y$ with respect to $x$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x_data = torch.tensor([0.5], requires_grad=True) # requires_grad = True\n",
    "\n",
    "y = 2.0 * x_data**5 + 1.0 \n",
    "\n",
    "y.backward() # 미분!\n",
    "\n",
    "x_data.grad.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{dy}{dx} = 10.0 \\cdot x ^ 4$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Exercise] Second-order derivative of a curve\n",
    "\n",
    "$y = x^2$\n",
    "\n",
    "Let's calculate the gradients of $y$ for each $x$ value of [-1.0, -0.75 -0.5, 0.0, 0.5, 0.75, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x_samples = [-1.0, -0.75, -0.5, 0.0, 0.5, 0.75, 1.0]\n",
    "\n",
    "grad_y_list = []\n",
    "\n",
    "# your code\n",
    "\n",
    "print(grad_y_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the meaning of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.plot(np.linspace(-1.2, 1.2, 100), np.linspace(-1.2, 1.2, 100)**2)\n",
    "\n",
    "plt.scatter(x_samples, [x**2 for x in x_samples], c =\"red\")\n",
    "\n",
    "dx = 0.1\n",
    "for x, grad_y in zip(x_samples, grad_y_list): \n",
    "    if grad_y > 0.0:\n",
    "        plt.plot([x, x + dx], [x**2, x**2 + grad_y * dx], color = 'blue')\n",
    "    elif grad_y < 0.0:\n",
    "        plt.plot([x, x - dx], [x**2, x**2 - grad_y * dx], color = 'blue')\n",
    "    else:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# x = 1.0\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "def my_func(x):\n",
    "    return x**2  # y = x*x\n",
    "\n",
    "\n",
    "def gradient_descent():\n",
    "    global x\n",
    "\n",
    "    y = my_func(x)\n",
    "\n",
    "    x.grad = None  # gradient update x\n",
    "    y.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x -= learning_rate * x.grad\n",
    "\n",
    "\n",
    "# animation code\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "axis = plt.axes(xlim=(-1.4, 1.4), ylim=(-0.2, 1.6))\n",
    "\n",
    "(line,) = plt.plot(np.linspace(-1.2, 1.2, 100), my_func(np.linspace(-1.2, 1.2, 100)))\n",
    "scatter = axis.scatter(x.detach().numpy(), my_func(x).detach().numpy(), c=\"red\")\n",
    "\n",
    "\n",
    "def init():\n",
    "    scatter.set_offsets(torch.cat([x, my_func(x)], dim=0).detach().numpy())\n",
    "    return (line, scatter)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    gradient_descent()\n",
    "    scatter.set_offsets(torch.cat([x, my_func(x)], dim=0).detach().numpy())\n",
    "    return (line, scatter)\n",
    "\n",
    "\n",
    "anim = FuncAnimation(fig, animate, init_func=init, frames=200, interval=1, blit=True)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
